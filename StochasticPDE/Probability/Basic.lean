/-
Copyright (c) 2025 ModularPhysics. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: ModularPhysics Contributors
-/
import Mathlib.MeasureTheory.Measure.MeasureSpace
import Mathlib.MeasureTheory.Integral.Bochner.Basic
import Mathlib.MeasureTheory.Function.ConditionalExpectation.Basic
import Mathlib.Probability.Independence.Basic
import Mathlib.Probability.Independence.Integration
import Mathlib.Probability.Moments.Variance
import Mathlib.Probability.ConditionalExpectation
import Mathlib.Probability.Distributions.Gaussian.Real

/-!
# Probability Theory Infrastructure

This file provides foundational probability theory definitions and lemmas
for the SPDE development, building on Mathlib's probability theory.

## Main Definitions

* `SubSigmaAlgebra` - Sub-σ-algebra of a measurable space
* `IndependentRandomVariables` - Independence of random variables
* `IsGaussian` - Gaussian distribution characterization

## References

* Durrett, "Probability: Theory and Examples"
* Williams, "Probability with Martingales"
-/

namespace SPDE.Probability

open MeasureTheory MeasurableSpace
open scoped MeasureTheory ENNReal

variable {Ω : Type*} [MeasurableSpace Ω] {μ : Measure Ω}

/-! ## Sub-σ-algebras -/

/-- A sub-σ-algebra is a measurable space structure that is coarser than the ambient one. -/
structure SubSigmaAlgebra (Ω : Type*) [m : MeasurableSpace Ω] where
  /-- The sub-σ-algebra -/
  measurableSpace : MeasurableSpace Ω
  /-- It is coarser than the ambient σ-algebra -/
  le : measurableSpace ≤ m

namespace SubSigmaAlgebra

variable {Ω : Type*} [MeasurableSpace Ω]

/-- The trivial sub-σ-algebra {∅, Ω} -/
def trivial : SubSigmaAlgebra Ω where
  measurableSpace := ⊥
  le := bot_le

/-- The full σ-algebra as a sub-σ-algebra -/
def full : SubSigmaAlgebra Ω where
  measurableSpace := ‹MeasurableSpace Ω›
  le := le_refl _

/-- A set is measurable w.r.t. the sub-σ-algebra -/
def MeasurableSet' (G : SubSigmaAlgebra Ω) (s : Set Ω) : Prop :=
  @MeasurableSet Ω G.measurableSpace s

/-- A function is measurable w.r.t. the sub-σ-algebra -/
def Measurable' (G : SubSigmaAlgebra Ω) {E : Type*} [MeasurableSpace E] (f : Ω → E) : Prop :=
  @Measurable Ω E G.measurableSpace _ f

/-- Intersection of two sub-σ-algebras -/
def inf (G₁ G₂ : SubSigmaAlgebra Ω) : SubSigmaAlgebra Ω where
  measurableSpace := G₁.measurableSpace ⊓ G₂.measurableSpace
  le := inf_le_of_left_le G₁.le

/-- σ-algebra generated by a set of sets.
    Requires that all generating sets are measurable in the ambient space. -/
def generate (s : Set (Set Ω)) (hs : ∀ t ∈ s, MeasurableSet t) : SubSigmaAlgebra Ω where
  measurableSpace := MeasurableSpace.generateFrom s
  le := MeasurableSpace.generateFrom_le hs

end SubSigmaAlgebra

/-! ## Conditional Expectation Properties

We use Mathlib's `MeasureTheory.condexp` and establish key properties.
The conditional expectation E[X | G] is the G-measurable function satisfying
∫_A E[X|G] dμ = ∫_A X dμ for all A ∈ G.
-/

section ConditionalExpectation

variable {E : Type*} [NormedAddCommGroup E] [NormedSpace ℝ E] [CompleteSpace E]

/-- Conditional expectation is AE-strongly measurable -/
theorem condexp_ae_measurable (G : MeasurableSpace Ω) (_hG : G ≤ ‹MeasurableSpace Ω›)
    (f : Ω → E) (_hf : Integrable f μ) :
    AEStronglyMeasurable (μ[f|G]) μ :=
  -- Follows from strong measurability of condexp
  (stronglyMeasurable_condExp (m := G)).aestronglyMeasurable

omit [MeasurableSpace Ω] in
/-- Tower property: E[E[X|G₁]|G₂] = E[X|G₂] when G₂ ⊆ G₁.
    Requires sigma-finiteness of the trimmed measure.
    The parameter `m₀` is the ambient measurable space (usually inferInstance). -/
theorem condexp_tower (m₀ : MeasurableSpace Ω) (G₁ : MeasurableSpace Ω) (hG₁ : G₁ ≤ m₀)
    {μ' : @Measure Ω m₀} [hσ : SigmaFinite (μ'.trim hG₁)]
    (G₂ : MeasurableSpace Ω) (hG₂ : G₂ ≤ G₁)
    (f : Ω → E) :
    μ'[μ'[f|G₁]|G₂] =ᵐ[μ'] μ'[f|G₂] :=
  condExp_condExp_of_le hG₂ hG₁

/-- Linearity of conditional expectation (addition) -/
theorem condexp_add' (G : MeasurableSpace Ω) (_hG : G ≤ ‹MeasurableSpace Ω›)
    (f g : Ω → E) (hf : Integrable f μ) (hg : Integrable g μ) :
    μ[f + g|G] =ᵐ[μ] μ[f|G] + μ[g|G] :=
  -- Mathlib's condExp_add handles this
  condExp_add hf hg G

/-- Linearity of conditional expectation (scalar multiplication) -/
theorem condexp_smul' (G : MeasurableSpace Ω) (_hG : G ≤ ‹MeasurableSpace Ω›)
    (c : ℝ) (f : Ω → E) :
    μ[c • f|G] =ᵐ[μ] c • μ[f|G] :=
  -- Mathlib's condExp_smul handles this
  condExp_smul c f G

/-- Jensen's inequality for conditional expectation: φ(E[f|G]) ≤ E[φ∘f|G] a.e.

    **Note**: This is Jensen's *inequality* for convex functions, not Jensen's functional
    equation (which characterizes linearity and is in `vNA/Spectral/JensenLinearity.lean`).

    **Status**: Requires infrastructure not yet in Mathlib.
    See comment in `Mathlib.MeasureTheory.Function.ConditionalExpectation.Real`:
    "should be generalized and proved using Jensen's inequality for the conditional
    expectation (not in mathlib yet)".

    The integral version `ConvexOn.map_average_le` from `Mathlib.Analysis.Convex.Integral`
    provides the unconditional version. The conditional version requires:
    1. Disintegration of the conditional expectation using regular conditional probabilities
    2. Application of Jensen's integral inequality for each fiber -/
theorem condexp_jensen (G : MeasurableSpace Ω) (_hG : G ≤ ‹MeasurableSpace Ω›)
    (_f : Ω → ℝ) (_hf : Integrable _f μ)
    (_φ : ℝ → ℝ) (_hφ_convex : ConvexOn ℝ Set.univ _φ)
    (_hφf : Integrable (_φ ∘ _f) μ) :
    ∀ᵐ ω ∂μ, _φ (μ[_f|G] ω) ≤ μ[_φ ∘ _f|G] ω := by
  sorry -- Requires infrastructure beyond current Mathlib

end ConditionalExpectation

/-! ## Independence -/

section Independence

variable {E : Type*} [MeasurableSpace E]

/-- Two random variables are independent if their σ-algebras are independent -/
def IndepRV (X : Ω → E) (Y : Ω → E) (μ : Measure Ω) : Prop :=
  ProbabilityTheory.IndepFun X Y μ

/-- A family of random variables is mutually independent.
    This is STRONGER than pairwise independence: all finite subcollections
    must be jointly independent.

    Expressed via σ-algebra independence: the σ-algebras σ(Xᵢ) are
    mutually independent in the sense of Mathlib's `iIndepFun`. -/
def IndepFamily {ι : Type*} (X : ι → Ω → E) (μ : Measure Ω) : Prop :=
  ProbabilityTheory.iIndepFun X μ

/-- Independent random variables: E[XY] = E[X]E[Y] -/
theorem indep_rv_integral_mul {X Y : Ω → ℝ} (h : IndepRV X Y μ)
    (hX : Integrable X μ) (hY : Integrable Y μ) [IsProbabilityMeasure μ] :
    ∫ ω, X ω * Y ω ∂μ = (∫ ω, X ω ∂μ) * (∫ ω, Y ω ∂μ) :=
  -- Uses Mathlib's IndepFun.integral_mul_eq_mul_integral
  h.integral_mul_eq_mul_integral hX.aestronglyMeasurable hY.aestronglyMeasurable

-- Independent of σ-algebra implies conditional expectation equals unconditional.
-- For a measurable function `f` that is `m₁`-measurable and independent of `m₂`,
-- we have `E[f|m₂] = E[f]` a.e. Use Mathlib's `condExp_indep_eq` directly:
--   condExp_indep_eq (hle₁ : m₁ ≤ m) (hle₂ : m₂ ≤ m) [SigmaFinite (μ.trim hle₂)]
--       (hf : StronglyMeasurable[m₁] f) (hindp : Indep m₁ m₂ μ) :
--       μ[f|m₂] =ᵐ[μ] fun _ => μ[f]

/-- Independent increments: for disjoint intervals, the increments are independent -/
def IndependentIncrements {ι : Type*} [Preorder ι]
    (X : ι → Ω → ℝ) (μ : Measure Ω) : Prop :=
  ∀ s t u v : ι, s ≤ t → t ≤ u → u ≤ v →
    IndepRV (fun ω => X t ω - X s ω) (fun ω => X v ω - X u ω) μ

end Independence

/-! ## Independence and Integral Factorization

This section provides the key lemmas connecting σ-algebra independence
to integral factorization, which is crucial for proving Brownian motion
is a martingale and for Itô isometry.

The main result: for a random variable X that is m₁-measurable and independent
of m₂, and for any A ∈ m₂, we have ∫_A X dμ = μ(A) * ∫ X dμ.

This follows from:
1. `condExp_indep_eq`: E[X | m₂] = E[X] a.e. when X is m₁-measurable and m₁ ⊥ m₂
2. The defining property of conditional expectation: ∫_A E[X|G] dμ = ∫_A X dμ for A ∈ G
-/

section IndepIntegral

open ProbabilityTheory

/-- Key lemma: For a random variable X independent of σ-algebra G, and A ∈ G,
    the integral over A equals μ(A) * E[X].

    This is the fundamental connection between σ-algebra independence and
    integral factorization, crucial for martingale proofs.

    Proof outline:
    1. By `condExp_indep_eq`, E[X|G] = E[X] a.e.
    2. By definition of condexp, ∫_A E[X|G] dμ = ∫_A X dμ for A ∈ G
    3. Combining: ∫_A X dμ = ∫_A E[X] dμ = E[X] * μ(A) -/
theorem setIntegral_of_indep_eq_measure_mul_integral
    {Ω : Type*} {m₀ : MeasurableSpace Ω} {m₁ m₂ : MeasurableSpace Ω}
    (hm₁ : m₁ ≤ m₀) (hm₂ : m₂ ≤ m₀)
    {μ : @Measure Ω m₀} [IsProbabilityMeasure μ] [SigmaFinite (μ.trim hm₂)]
    {f : Ω → ℝ}
    (hf_meas : StronglyMeasurable[m₁] f)
    (hf_int : Integrable f μ)
    (hindep : Indep m₁ m₂ μ)
    (A : Set Ω) (hA : @MeasurableSet Ω m₂ A) :
    ∫ ω in A, f ω ∂μ = (μ A).toReal * ∫ ω, f ω ∂μ := by
  -- Step 1: By condExp_indep_eq, E[f | m₂] = E[f] a.e.
  have hcondexp : μ[f|m₂] =ᵐ[μ] fun _ => ∫ ω, f ω ∂μ := condExp_indep_eq hm₁ hm₂ hf_meas hindep
  -- Step 2: ∫_A E[f|m₂] dμ = ∫_A f dμ (defining property)
  have hdefining : ∫ ω in A, f ω ∂μ = ∫ ω in A, μ[f|m₂] ω ∂μ := (setIntegral_condExp hm₂ hf_int hA).symm
  -- Step 3: ∫_A E[f|m₂] dμ = ∫_A E[f] dμ (using ae equality)
  have hae_int : ∫ ω in A, μ[f|m₂] ω ∂μ = ∫ ω in A, (∫ ω', f ω' ∂μ) ∂μ := by
    apply setIntegral_congr_ae (hm₂ A hA)
    filter_upwards [hcondexp] with ω hω _
    exact hω
  -- Step 4: ∫_A c dμ = c * μ(A) for constant c
  have hconst : ∫ ω in A, (∫ ω', f ω' ∂μ) ∂μ = (∫ ω', f ω' ∂μ) * (μ A).toReal := by
    rw [setIntegral_const, smul_eq_mul, mul_comm, Measure.real_def]
  -- Combine
  calc ∫ ω in A, f ω ∂μ
      = ∫ ω in A, μ[f|m₂] ω ∂μ := hdefining
    _ = ∫ ω in A, (∫ ω', f ω' ∂μ) ∂μ := hae_int
    _ = (∫ ω', f ω' ∂μ) * (μ A).toReal := hconst
    _ = (μ A).toReal * ∫ ω', f ω' ∂μ := mul_comm _ _

/-- Corollary: If X has zero mean and is independent of G, then ∫_A X dμ = 0 for all A ∈ G.
    This is the key lemma for proving Brownian motion is a martingale. -/
theorem setIntegral_eq_zero_of_indep_zero_mean
    {Ω : Type*} {m₀ : MeasurableSpace Ω} {m₁ m₂ : MeasurableSpace Ω}
    (hm₁ : m₁ ≤ m₀) (hm₂ : m₂ ≤ m₀)
    {μ : @Measure Ω m₀} [IsProbabilityMeasure μ] [SigmaFinite (μ.trim hm₂)]
    {f : Ω → ℝ}
    (hf_meas : StronglyMeasurable[m₁] f)
    (hf_int : Integrable f μ)
    (hindep : Indep m₁ m₂ μ)
    (hmean : ∫ ω, f ω ∂μ = 0)
    (A : Set Ω) (hA : @MeasurableSet Ω m₂ A) :
    ∫ ω in A, f ω ∂μ = 0 := by
  rw [setIntegral_of_indep_eq_measure_mul_integral hm₁ hm₂ hf_meas hf_int hindep A hA, hmean, mul_zero]

/-- For the comap σ-algebra: a function f is strongly measurable w.r.t. comap f inferInstance.
    This is needed to apply the above lemmas to Brownian motion increments. -/
theorem stronglyMeasurable_comap_self {Ω : Type*} [MeasurableSpace Ω]
    (f : Ω → ℝ) :
    StronglyMeasurable[MeasurableSpace.comap f inferInstance] f := by
  -- f is measurable w.r.t. comap f m by definition of comap
  -- The comap σ-algebra is exactly the σ-algebra that makes f measurable
  have hmeas : @Measurable Ω ℝ (MeasurableSpace.comap f inferInstance) _ f := by
    intro s hs
    -- s is a measurable set in ℝ, need to show f⁻¹(s) is measurable in comap f
    -- By definition of comap, the measurable sets are exactly f⁻¹(measurable sets)
    exact ⟨s, hs, rfl⟩
  exact hmeas.stronglyMeasurable

/-- The comap σ-algebra is always ≤ the ambient σ-algebra when f is measurable. -/
theorem comap_le_of_measurable' {Ω : Type*} {m : MeasurableSpace Ω}
    {f : Ω → ℝ} (hf : @Measurable Ω ℝ m _ f) :
    MeasurableSpace.comap f inferInstance ≤ m :=
  MeasurableSpace.comap_le_iff_le_map.mpr (fun _ hs => hf hs)

/-- Version with explicit σ-algebra generated by a random variable.
    If X generates m₁ and m₁ ⊥ m₂, then for A ∈ m₂:
    ∫_A X dμ = μ(A) * E[X] -/
theorem setIntegral_of_indep_comap
    {Ω : Type*} {m₀ : MeasurableSpace Ω}
    {μ : @Measure Ω m₀} [IsProbabilityMeasure μ]
    {m₂ : MeasurableSpace Ω} (hm₂ : m₂ ≤ m₀)
    [SigmaFinite (μ.trim hm₂)]
    (f : Ω → ℝ) (hf_meas : @Measurable Ω ℝ m₀ _ f)
    (hf_int : Integrable f μ)
    (hindep : Indep (MeasurableSpace.comap f inferInstance) m₂ μ)
    (A : Set Ω) (hA : @MeasurableSet Ω m₂ A) :
    ∫ ω in A, f ω ∂μ = (μ A).toReal * ∫ ω, f ω ∂μ := by
  have hm₁ : MeasurableSpace.comap f inferInstance ≤ m₀ := comap_le_of_measurable' hf_meas
  have hf_sm : StronglyMeasurable[MeasurableSpace.comap f inferInstance] f :=
    stronglyMeasurable_comap_self f
  exact setIntegral_of_indep_eq_measure_mul_integral hm₁ hm₂ hf_sm hf_int hindep A hA

/-- Zero mean version for comap σ-algebra. -/
theorem setIntegral_eq_zero_of_indep_comap_zero_mean
    {Ω : Type*} {m₀ : MeasurableSpace Ω}
    {μ : @Measure Ω m₀} [IsProbabilityMeasure μ]
    {m₂ : MeasurableSpace Ω} (hm₂ : m₂ ≤ m₀)
    [SigmaFinite (μ.trim hm₂)]
    (f : Ω → ℝ) (hf_meas : @Measurable Ω ℝ m₀ _ f)
    (hf_int : Integrable f μ)
    (hindep : Indep (MeasurableSpace.comap f inferInstance) m₂ μ)
    (hmean : ∫ ω, f ω ∂μ = 0)
    (A : Set Ω) (hA : @MeasurableSet Ω m₂ A) :
    ∫ ω in A, f ω ∂μ = 0 := by
  rw [setIntegral_of_indep_comap hm₂ f hf_meas hf_int hindep A hA, hmean, mul_zero]

end IndepIntegral

/-! ## Gaussian Distribution -/

section Gaussian

open ProbabilityTheory

/-- A random variable X has Gaussian distribution N(m, v) if its characteristic function
    is E[exp(itX)] = exp(itm - vt^2/2). We characterize this via moment conditions. -/
structure IsGaussian (X : Ω → ℝ) (μ : Measure Ω) (mean : ℝ) (variance : ℝ) : Prop where
  /-- Variance is non-negative -/
  variance_nonneg : variance ≥ 0
  /-- Integrability -/
  integrable : Integrable X μ
  /-- Mean condition -/
  mean_eq : ∫ ω, X ω ∂μ = mean
  /-- Variance condition -/
  variance_eq : ∫ ω, (X ω - mean)^2 ∂μ = variance
  /-- Characteristic function condition (captures Gaussianity beyond just mean/variance) -/
  char_function : ∀ t : ℝ, ∫ ω, Complex.exp (Complex.I * t * X ω) ∂μ =
    Complex.exp (Complex.I * t * mean - variance * t^2 / 2)

/-- From the characteristic function at t=0, a Gaussian RV lives on a probability space. -/
theorem IsGaussian.isProbabilityMeasure {X : Ω → ℝ} {μ : Measure Ω} {mean variance : ℝ}
    (h : IsGaussian X μ mean variance) : IsProbabilityMeasure μ := by
  -- At t=0: ∫ exp(I·0·X) dμ = exp(0) = 1, i.e., ∫ 1 dμ = 1
  have h0 : ∫ ω, (1 : ℂ) ∂μ = 1 := by
    have hcf := h.char_function 0
    simp only [Complex.ofReal_zero, mul_zero, zero_mul, Complex.exp_zero] at hcf
    -- hcf : ∫ ω, 1 ∂μ = Complex.exp (0 - ↑variance * 0 ^ 2 / 2)
    -- The remaining RHS exponent simplifies to 0
    rw [show (0 : ℂ) - ↑variance * (0 : ℂ) ^ 2 / 2 = 0 from by ring,
        Complex.exp_zero] at hcf
    exact hcf
  -- Since ∫ 1 dμ ≠ 0, the constant function is integrable
  have h_int : Integrable (fun _ : Ω => (1 : ℂ)) μ := by
    by_contra h_not; simp [integral_undef h_not] at h0
  -- Integrable constant implies finite measure
  have _hfin : IsFiniteMeasure μ := by
    constructor
    calc μ Set.univ = ∫⁻ _, 1 ∂μ := (lintegral_one).symm
      _ = ∫⁻ a, ‖(fun _ : Ω => (1 : ℂ)) a‖ₑ ∂μ := by congr 1; ext; simp
      _ < ⊤ := h_int.hasFiniteIntegral
  -- Extract μ(Ω) = 1 via ofReal embedding
  constructor
  suffices h_univ : (μ Set.univ).toReal = 1 by
    rw [← ENNReal.ofReal_toReal (measure_ne_top μ Set.univ), h_univ, ENNReal.ofReal_one]
  -- Get real-valued integral from complex-valued one
  have h_real : ∫ ω, (1 : ℝ) ∂μ = 1 := by
    have key : (↑(∫ ω, (1 : ℝ) ∂μ) : ℂ) = 1 := by
      exact ((@integral_ofReal Ω _ μ ℂ _ (fun _ => (1 : ℝ))).symm).trans h0
    exact_mod_cast key
  rw [integral_const, smul_eq_mul, mul_one, measureReal_def] at h_real
  exact h_real

/-- The pushforward of μ by a Gaussian RV X is the Gaussian measure on ℝ. -/
theorem IsGaussian.map_eq_gaussianReal {X : Ω → ℝ} {μ : Measure Ω} {mean variance : ℝ}
    (h : IsGaussian X μ mean variance) :
    μ.map X = gaussianReal mean ⟨variance, h.variance_nonneg⟩ := by
  have := h.isProbabilityMeasure
  have hX_am : AEMeasurable X μ := h.integrable.aemeasurable
  apply Measure.ext_of_charFun
  ext t
  rw [charFun_apply_real, integral_map hX_am (by fun_prop), charFun_gaussianReal]
  -- LHS: ∫ ω, exp(t * X ω * I) ∂μ, need to match h.char_function t
  have hcf := h.char_function t
  -- Rewrite: t * X ω * I = I * t * X ω (commutativity in ℂ)
  simp_rw [show ∀ ω, (t : ℂ) * ↑(X ω) * Complex.I = Complex.I * ↑t * ↑(X ω) from
    fun ω => by ring]
  rw [hcf]; congr 1
  simp only [NNReal.coe_mk]; ring

/-- All moments of a Gaussian random variable exist. The pushforward μ.map X is the
    Gaussian measure on ℝ, which has all moments finite via `integrableExpSet = Set.univ`. -/
theorem IsGaussian.all_moments {X : Ω → ℝ} {μ : Measure Ω} {mean variance : ℝ}
    (h : IsGaussian X μ mean variance) :
    ∀ n : ℕ, Integrable (fun ω => (X ω)^n) μ := by
  intro n
  have _hprob := h.isProbabilityMeasure
  have hX_am : AEMeasurable X μ := h.integrable.aemeasurable
  have hmap := h.map_eq_gaussianReal
  -- |x|^n is integrable against gaussianReal via integrableExpSet = Set.univ
  open ProbabilityTheory in
  have hint_abs : Integrable (fun x : ℝ => |x| ^ n)
      (gaussianReal mean ⟨variance, h.variance_nonneg⟩) := by
    apply integrable_pow_abs_of_mem_interior_integrableExpSet _ n
    simp only [← Function.id_def, integrableExpSet_id_gaussianReal, interior_univ, Set.mem_univ]
  -- Transfer via pushforward: μ.map X = gaussianReal mean v
  rw [← hmap] at hint_abs
  have hint_abs_X : Integrable (fun ω => |X ω| ^ n) μ :=
    hint_abs.comp_aemeasurable hX_am
  -- (X ω)^n is integrable since ‖(X ω)^n‖ = |X ω|^n = ‖|X ω|^n‖
  exact hint_abs_X.mono (h.integrable.aestronglyMeasurable.pow n)
    (by filter_upwards with ω; simp [norm_pow, Real.norm_eq_abs])

/-- Standard normal distribution N(0, 1) -/
def IsStandardNormal (X : Ω → ℝ) (μ : Measure Ω) : Prop :=
  IsGaussian X μ 0 1

/-- Gaussian is preserved under affine transformation -/
theorem gaussian_affine {X : Ω → ℝ} {μ : Measure Ω} [IsProbabilityMeasure μ] {m v : ℝ}
    (hX : IsGaussian X μ m v) (a b : ℝ) :
    IsGaussian (fun ω => a * X ω + b) μ (a * m + b) (a^2 * v) where
  variance_nonneg := mul_nonneg (sq_nonneg a) hX.variance_nonneg
  integrable := (hX.integrable.const_mul a).add (integrable_const b)
  mean_eq := by
    rw [integral_add (hX.integrable.const_mul a) (integrable_const b)]
    rw [integral_const_mul, integral_const, smul_eq_mul]
    simp only [probReal_univ, one_mul, hX.mean_eq]
  variance_eq := by
    have h : (fun ω => (a * X ω + b - (a * m + b))^2) = (fun ω => a^2 * (X ω - m)^2) := by
      ext ω; ring
    rw [h, integral_const_mul, hX.variance_eq]
  char_function := fun t => by
    -- Show the integrands are equal pointwise
    have heq : ∀ ω, Complex.exp (Complex.I * t * ↑(a * X ω + b)) =
               Complex.exp (Complex.I * t * b) * Complex.exp (Complex.I * (t * a) * X ω) := fun ω => by
      rw [← Complex.exp_add]
      congr 1
      simp only [Complex.ofReal_add, Complex.ofReal_mul]
      ring
    -- Casting helper: ↑t * ↑a = ↑(t * a)
    have hcast : ∀ ω : Ω, Complex.exp (Complex.I * (↑t * ↑a) * ↑(X ω)) =
                 Complex.exp (Complex.I * ↑(t * a) * ↑(X ω)) := fun _ => by
      simp only [Complex.ofReal_mul]
    -- Rewrite the integral using integral_congr_ae
    have hint : ∫ ω, Complex.exp (Complex.I * t * ↑(a * X ω + b)) ∂μ =
                Complex.exp (Complex.I * t * b) * ∫ ω, Complex.exp (Complex.I * (t * a) * X ω) ∂μ := by
      have h1 : ∫ ω, Complex.exp (Complex.I * t * ↑(a * X ω + b)) ∂μ =
                ∫ ω, Complex.exp (Complex.I * t * b) * Complex.exp (Complex.I * (t * a) * X ω) ∂μ := by
        apply integral_congr_ae; filter_upwards with ω; exact heq ω
      rw [h1]
      exact integral_const_mul _ _
    rw [hint]
    -- Apply char_function with casting adjustment
    have h2 : ∫ ω, Complex.exp (Complex.I * (↑t * ↑a) * ↑(X ω)) ∂μ =
              ∫ ω, Complex.exp (Complex.I * ↑(t * a) * ↑(X ω)) ∂μ := by
      apply integral_congr_ae; filter_upwards with ω; exact hcast ω
    rw [h2, hX.char_function (t * a)]
    -- Simplify: exp(itb) * exp(i(ta)m - v(ta)^2/2) = exp(it(am+b) - a^2*v*t^2/2)
    rw [← Complex.exp_add]
    congr 1
    simp only [Complex.ofReal_add, Complex.ofReal_mul, Complex.ofReal_pow]
    ring

/-- Sum of independent Gaussians is Gaussian.
    The proof uses the characteristic function approach: for independent X, Y,
    E[exp(it(X+Y))] = E[exp(itX)] * E[exp(itY)]. -/
theorem gaussian_sum_indep {X Y : Ω → ℝ} {μ : Measure Ω} [IsProbabilityMeasure μ]
    {m₁ m₂ v₁ v₂ : ℝ}
    (hX : IsGaussian X μ m₁ v₁) (hY : IsGaussian Y μ m₂ v₂)
    (hindep : IndepRV X Y μ) :
    IsGaussian (fun ω => X ω + Y ω) μ (m₁ + m₂) (v₁ + v₂) where
  variance_nonneg := add_nonneg hX.variance_nonneg hY.variance_nonneg
  integrable := hX.integrable.add hY.integrable
  mean_eq := by
    rw [integral_add hX.integrable hY.integrable, hX.mean_eq, hY.mean_eq]
  variance_eq := by
    -- Var(X+Y) = Var(X) + Var(Y) for independent RVs (covariance = 0)
    have hXsq : Integrable (fun ω => X ω ^ 2) μ := hX.all_moments 2
    have hYsq : Integrable (fun ω => Y ω ^ 2) μ := hY.all_moments 2
    have hXmem : MemLp X 2 μ :=
      (memLp_two_iff_integrable_sq hX.integrable.aestronglyMeasurable).mpr hXsq
    have hYmem : MemLp Y 2 μ :=
      (memLp_two_iff_integrable_sq hY.integrable.aestronglyMeasurable).mpr hYsq
    -- Use Mathlib's variance_add for independent RVs
    have hvar := hindep.variance_add hXmem hYmem
    -- Convert to our definition using mean_eq
    have hXvar : ProbabilityTheory.variance X μ = v₁ := by
      rw [ProbabilityTheory.variance_eq_integral hX.integrable.aemeasurable, hX.mean_eq]
      exact hX.variance_eq
    have hYvar : ProbabilityTheory.variance Y μ = v₂ := by
      rw [ProbabilityTheory.variance_eq_integral hY.integrable.aemeasurable, hY.mean_eq]
      exact hY.variance_eq
    -- Now compute
    have hmean : ∫ ω, (X ω + Y ω) ∂μ = m₁ + m₂ := by
      rw [integral_add hX.integrable hY.integrable, hX.mean_eq, hY.mean_eq]
    calc ∫ ω, (X ω + Y ω - (m₁ + m₂))^2 ∂μ
        = ∫ ω, (X ω + Y ω - ∫ ω', (X ω' + Y ω') ∂μ)^2 ∂μ := by rw [hmean]
      _ = ProbabilityTheory.variance (X + Y) μ :=
          (ProbabilityTheory.variance_eq_integral (hX.integrable.add hY.integrable).aemeasurable).symm
      _ = ProbabilityTheory.variance X μ + ProbabilityTheory.variance Y μ := hvar
      _ = v₁ + v₂ := by rw [hXvar, hYvar]
  char_function := fun t => by
    -- E[exp(it(X+Y))] = E[exp(itX) * exp(itY)] = E[exp(itX)] * E[exp(itY)]
    -- by independence of X and Y
    -- First, convert the integrand using Complex.ofReal_add
    have hconv : ∀ ω, Complex.exp (Complex.I * t * ↑(X ω + Y ω)) =
                 Complex.exp (Complex.I * t * ↑(X ω) + Complex.I * t * ↑(Y ω)) := fun ω => by
      congr 1
      rw [Complex.ofReal_add]
      ring
    -- Then split exp(a + b) = exp(a) * exp(b)
    have heq : ∀ ω, Complex.exp (Complex.I * t * ↑(X ω + Y ω)) =
               Complex.exp (Complex.I * t * ↑(X ω)) * Complex.exp (Complex.I * t * ↑(Y ω)) := fun ω => by
      rw [hconv ω, Complex.exp_add]
    calc ∫ ω, Complex.exp (Complex.I * t * ↑(X ω + Y ω)) ∂μ
        = ∫ ω, Complex.exp (Complex.I * t * ↑(X ω)) * Complex.exp (Complex.I * t * ↑(Y ω)) ∂μ := by
            apply integral_congr_ae; filter_upwards with ω; exact heq ω
      _ = (∫ ω, Complex.exp (Complex.I * t * ↑(X ω)) ∂μ) *
          (∫ ω, Complex.exp (Complex.I * t * ↑(Y ω)) ∂μ) := by
            -- Use independence: exp(itX) ⟂ exp(itY) since X ⟂ Y
            -- For f = exp(it·) : ℝ → ℂ, we have f ∘ X ⟂ f ∘ Y
            let f : ℝ → ℂ := fun x => Complex.exp (Complex.I * t * ↑x)
            -- Rewrite integrand to use f
            have hlhs : ∫ ω, Complex.exp (Complex.I * t * ↑(X ω)) *
                            Complex.exp (Complex.I * t * ↑(Y ω)) ∂μ =
                        ∫ ω, f (X ω) * f (Y ω) ∂μ := rfl
            have hrhs1 : ∫ ω, Complex.exp (Complex.I * t * ↑(X ω)) ∂μ =
                         ∫ ω, f (X ω) ∂μ := rfl
            have hrhs2 : ∫ ω, Complex.exp (Complex.I * t * ↑(Y ω)) ∂μ =
                         ∫ ω, f (Y ω) ∂μ := rfl
            rw [hlhs, hrhs1, hrhs2]
            apply hindep.integral_fun_comp_mul_comp
            · exact hX.integrable.aemeasurable
            · exact hY.integrable.aemeasurable
            · -- f is continuous, hence AEStronglyMeasurable
              have hf_cont : Continuous f := by
                apply Complex.continuous_exp.comp
                exact continuous_const.mul Complex.continuous_ofReal
              exact hf_cont.aestronglyMeasurable
            · have hf_cont : Continuous f := by
                apply Complex.continuous_exp.comp
                exact continuous_const.mul Complex.continuous_ofReal
              exact hf_cont.aestronglyMeasurable
      _ = Complex.exp (Complex.I * t * ↑m₁ - ↑v₁ * ↑t^2 / 2) *
          Complex.exp (Complex.I * t * ↑m₂ - ↑v₂ * ↑t^2 / 2) := by
            rw [hX.char_function t, hY.char_function t]
      _ = Complex.exp (Complex.I * t * ↑(m₁ + m₂) - ↑(v₁ + v₂) * ↑t^2 / 2) := by
            rw [← Complex.exp_add]
            congr 1
            rw [Complex.ofReal_add, Complex.ofReal_add]
            ring

end Gaussian

/-! ## Moment Bounds -/

section Moments

variable {X : Ω → ℝ}

/-- Chebyshev's inequality: P(|X - E[X]| ≥ ε) ≤ Var(X) / ε² -/
theorem chebyshev_ineq [IsProbabilityMeasure μ]
    (hX : MemLp X 2 μ) (ε : ℝ) (hε : ε > 0) :
    μ {ω | |X ω - ∫ ω', X ω' ∂μ| ≥ ε} ≤
      ENNReal.ofReal ((∫ ω, (X ω - ∫ ω', X ω' ∂μ)^2 ∂μ) / ε^2) := by
  -- Use Mathlib's Chebyshev inequality directly
  have h := ProbabilityTheory.meas_ge_le_variance_div_sq hX hε
  -- Convert variance to explicit integral
  have hvar : ProbabilityTheory.variance X μ = ∫ ω, (X ω - ∫ ω', X ω' ∂μ)^2 ∂μ :=
    ProbabilityTheory.variance_eq_integral hX.aemeasurable
  rw [hvar] at h
  convert h using 2

/-- Markov's inequality: P(X ≥ a) ≤ E[X] / a for nonnegative X -/
theorem markov_ineq [IsProbabilityMeasure μ]
    (hX : Integrable X μ) (hX_nonneg : ∀ᵐ ω ∂μ, X ω ≥ 0)
    (a : ℝ) (ha : a > 0) :
    μ {ω | X ω ≥ a} ≤ ENNReal.ofReal ((∫ ω, X ω ∂μ) / a) := by
  -- Use Mathlib's Markov inequality: a * μ.real {x | a ≤ X x} ≤ ∫ x, X x ∂μ
  have h := mul_meas_ge_le_integral_of_nonneg hX_nonneg hX a
  -- From a * μ.real {x | a ≤ X x} ≤ ∫ x, X x ∂μ, divide by a
  have hdiv : μ.real {ω | a ≤ X ω} ≤ (∫ ω, X ω ∂μ) / a := by
    rw [le_div_iff₀ ha, mul_comm]
    exact h
  -- Convert μ.real to μ using ofReal_measureReal
  have hset : {ω | X ω ≥ a} = {ω | a ≤ X ω} := by ext; simp [ge_iff_le]
  rw [hset, ← ofReal_measureReal (measure_ne_top μ _)]
  exact ENNReal.ofReal_le_ofReal hdiv

/-- Doob's maximal inequality for martingales (L^2 version).

    For a martingale (Xₜ) with E[Xₜ²] < ∞, the maximal function X* = sup_{s≤t} |Xₛ|
    satisfies E[(X*)²] ≤ 4 * E[Xₜ²].

    **Status**: Requires developing Doob's Lp inequality from the L^1 maximal inequality.
    Mathlib has `MeasureTheory.Submartingale.maximal_ineq` in
    `Mathlib.Probability.Martingale.OptionalStopping` for the L^1 version:
    `ε • μ {ε ≤ f* n} ≤ ∫ ω in {ε ≤ f* n}, f n ω ∂μ`

    The L^2 version follows from:
    1. Apply the L^1 maximal inequality
    2. Use Hölder's inequality and integration by parts
    3. The constant 4 = (p/(p-1))^p for p = 2 -/
theorem doob_maximal_L2 {ι : Type*} [Preorder ι] [Countable ι]
    {F : ι → MeasurableSpace Ω} (_X : ι → Ω → ℝ)
    (_hmg : ∀ s t : ι, s ≤ t → ∀ A, @MeasurableSet Ω (F s) A →
      ∫ ω in A, _X t ω ∂μ = ∫ ω in A, _X s ω ∂μ)
    (_hX : ∀ i, Integrable (fun ω => (_X i ω)^2) μ)
    (T : ι) :
    ∫ ω, (⨆ i : {i : ι // i ≤ T}, |_X i ω|)^2 ∂μ ≤ 4 * ∫ ω, (_X T ω)^2 ∂μ := by
  sorry -- Requires Doob's Lp inequality from L^1 maximal inequality

end Moments

end SPDE.Probability
